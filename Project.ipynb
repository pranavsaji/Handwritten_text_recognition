{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb167f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/pranavsaji/opt/anaconda3/lib/python3.9/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/pranavsaji/opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57cdb6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.20.0 in /Users/pranavsaji/opt/anaconda3/lib/python3.9/site-packages (1.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "from itertools import groupby\n",
    "import re\n",
    "import cv2  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fb88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv('Validation.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "shapetrain = train.shape\n",
    "shapeval = val.shape\n",
    "shapetest = test.shape\n",
    "print(\"Train DataFrame shape:\", shapetrain)\n",
    "print(\"Val DataFrame shape:\", shapeval)\n",
    "print(\"Test DataFrame shape:\", shapetest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcfecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = ['Image Path', 'Word']\n",
    "val.columns = ['Image Path', 'Word']\n",
    "test.columns = ['Image Path', 'Word']\n",
    "print(val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baabc646",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "null_values = train.isnull()\n",
    "\n",
    "rows_with_null = train[null_values.any(axis=1)]\n",
    "\n",
    "print(\"Rows with null values:\")\n",
    "print(rows_with_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d554ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = train.at[159, 'Image Path']\n",
    "word_of_image = train.at[159, 'Word']\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')  # Hide axis labels\n",
    "plt.show()\n",
    "word_of_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdfbc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_dataset_inplace(dataset):\n",
    "    # Check for null values in the dataset\n",
    "    null_values = dataset.isnull()\n",
    "    null = null_values.any().any()\n",
    "    print(\"Are there any null values in the DataFrame?\", null)\n",
    "\n",
    "   \n",
    "    for index, row in dataset.iterrows():\n",
    "        if null_values.iloc[index].any():\n",
    "            pattern = r'(\\d{4})\\.jpeg$'\n",
    "            match = re.search(pattern, dataset.at[index, 'Image Path'])\n",
    "            if match:\n",
    "                extracted_number = match.group(1)\n",
    "                \n",
    "                dataset.at[index, 'Word'] = extracted_number\n",
    "\n",
    "process_dataset_inplace(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = train.at[159, 'Image Path']\n",
    "word_of_image = train.at[159, 'Word']\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off') \n",
    "plt.show()\n",
    "word_of_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset_inplace(val)\n",
    "process_dataset_inplace(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ac7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_random_images(train,path, num_images=5):\n",
    "\n",
    "    random_indices = random.sample(range(len(train)), num_images)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        \n",
    "        image_path =train.at[idx, 'Image Path']\n",
    "        word_of_image = train.at[idx, 'Word']\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Create a subplot for each image\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Word: {word_of_image}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "display_random_images(test,\"test/\", num_images=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec648c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the characters you want to support, including uppercase, lowercase, and digits\n",
    "alphabets = string.ascii_letters + string.digits + \" ' -\"\n",
    "\n",
    "max_str_len = 24  # max length of input labels\n",
    "num_of_characters = len(alphabets) + 1\n",
    "num_of_timestamps = 64  # max length of predicted labels: 64\n",
    "batch_size = 512\n",
    "\n",
    "def encode_and_pad_strings(text):\n",
    "    # Initialize an empty list to store the encoded values for the string\n",
    "    # Encoding each output word into digits\n",
    "    dig_list = []\n",
    "    for char in str(text):\n",
    "        idx = alphabets.find(char)\n",
    "        dig_list.append(idx if idx != -1 else alphabets.find('-'))\n",
    "\n",
    "    return pad_sequences([dig_list], maxlen=max_str_len, padding='post', value=-1)[0]\n",
    "\n",
    "# Example usage\n",
    "input_string = \"A9ello world\"\n",
    "result = encode_and_pad_strings(input_string)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f85ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_padded_sequence(padded_sequence):\n",
    "    text = ''\n",
    "    for number in padded_sequence:\n",
    "        if number == -1: # CTC blank\n",
    "            break\n",
    "        else:\n",
    "            text += alphabets[number]\n",
    "\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "input_string = \"Hello world\"\n",
    "encoded_result = encode_and_pad_strings(input_string)\n",
    "print(\"Encoded Sequence:\", encoded_result)\n",
    "\n",
    "decoded_result = decode_padded_sequence(encoded_result)\n",
    "print(\"Decoded String:\", decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67871e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def preprocess_image(image_path, label, label_len):\n",
    "    target_height = 256\n",
    "    target_width= 64\n",
    "\n",
    "    file = tf.io.read_file(image_path)\n",
    "\n",
    "    image = tf.image.decode_png(file, channels=1)\n",
    "\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    original_height = tf.shape(image)[0]\n",
    "    original_width = tf.shape(image)[1]\n",
    "    aspect_ratio = tf.cast(original_width, tf.float32) / tf.cast(original_height, tf.float32)\n",
    "    \n",
    "    new_width = tf.cast(target_height, tf.float32) * aspect_ratio\n",
    "    \n",
    "    image = tf.image.resize(image, [target_height, tf.cast(new_width, tf.int32)])\n",
    "    \n",
    "    return image, label, label_len\n",
    "\n",
    "\n",
    "image_path = \"train/0001-1-1-6-Hexagons.jpeg\"\n",
    "imagex, label, label_len = preprocess_image(image_path, label, label_len)\n",
    "num_of_timestamps = 64\n",
    "\n",
    "plt.imshow(imagex.numpy().squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f703c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_list(dataset, img_dir):\n",
    "    data_x, data_y, label_len = [], [], []\n",
    "    for idx, row in dataset.iterrows():\n",
    "        if isinstance(row['Word'], str):\n",
    "            text = row['Word']\n",
    "            label_len.append(len(text))\n",
    "            data_y.append(encode_and_pad_strings(text))\n",
    "            data_x.append(row['Image Path'])\n",
    "        \n",
    "    return data_x, data_y, label_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb29249",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = \"train\"\n",
    "val_img_dir = \"val\"\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def create_tf_dataset(data_x, data_y, label_len):\n",
    "    data_xx = tf.constant(data_x, dtype=tf.string)\n",
    "    data_yy = tf.constant(data_y, dtype=tf.int64)\n",
    "    label_lenn = tf.constant(label_len, dtype=tf.int64)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data_xx, data_yy, label_lenn))\n",
    "    dataset = dataset.map(preprocess_image, num_parallel_calls=AUTOTUNE).batch(batch_size)\n",
    "    dataset = dataset.map(lambda *x: (x[0:-1],x[-1])).prefetch(AUTOTUNE).prefetch(buffer_size=AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_x, train_y, train_label_len = create_data_list(train,train_img_dir)\n",
    "train_dataset = create_tf_dataset(train_x, train_y, train_label_len)\n",
    "\n",
    "val_x, val_y, val_label_len = create_data_list(val,val_img_dir)\n",
    "val_dataset = create_tf_dataset(val_x, val_y, val_label_len)\n",
    "\n",
    "print(len(train_y), len(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9728ac1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
